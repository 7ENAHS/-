import { GoogleGenAI } from "@google/genai";

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

/**
 * Sends the image and shoe prompt to Gemini for editing.
 * @param base64Image The base64 encoded string of the original image (without data prefix if possible, but we clean it).
 * @param shoeDescription The description of the shoe to generate.
 * @returns The base64 string of the generated image.
 */
export const generateVirtualTryOn = async (
  base64Image: string,
  shoeDescription: string
): Promise<string> => {
  try {
    // Ensure clean base64 string
    const cleanBase64 = base64Image.replace(/^data:image\/(png|jpeg|jpg|webp);base64,/, '');

    const prompt = `Edit this image to replace the shoes on the person's feet with ${shoeDescription}. 
    Ensure the new shoes fit the feet naturally, matching the lighting, perspective, and skin tone of the original image. 
    Maintain the rest of the image (legs, background, clothing) exactly as is. 
    If the feet are barefoot, put the shoes on them.`;

    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: {
        parts: [
          {
            inlineData: {
              mimeType: 'image/jpeg',
              data: cleanBase64
            }
          },
          {
            text: prompt
          }
        ]
      }
    });

    // Check for image in response safely
    const candidates = response.candidates;
    if (candidates && candidates.length > 0) {
        const content = candidates[0].content;
        if (content && content.parts) {
            for (const part of content.parts) {
                if (part.inlineData && part.inlineData.data) {
                    return `data:image/png;base64,${part.inlineData.data}`;
                }
            }
        }
    }
    
    throw new Error("No image generated by the model.");

  } catch (error) {
    console.error("Gemini API Error:", error);
    throw error;
  }
};